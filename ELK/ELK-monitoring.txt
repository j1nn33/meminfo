	Метрики мониторинга ELK

=============================================
     Уровень сервера
=============================================

- Загрузка процессорных ядер и общее LA;
- Использование памяти;
- Пинг до сервера и время отклика;
- i/o по дисковой подсистеме;
- Остаток свободного места на дисках (настройка watermark.low 
  по умолчанию запрещает эластику создавать новые индексы при 
  наличии менее 85% свободного места );
- Использование сети и, особенно, коллизии и ошибки на интерфейсах.
  (Если на каком-то этапе нода не ответила на пинг в течение 30 секунд, 
   то она помечается как недоступная, с последствиями в виде ребаланса 
   кластера и долгих проверок целостности.)

=============================================
    Уровень сервиса
=============================================

- Количество запущенных процессов сервиса elasticsearch;
- Используемая сервисом память;
- Пинг до порта приложения (стандартные порты elasticsearch/kibana — 9200/9300/5601).

Если любая из метрик упала в ноль — это, означает что приложение упало,
либо зависло, и немедленно вызывается алерт по уровню disaster.

=============================================
     Уровень приложения
=============================================
Уровень Кластера

_cluster/health

- status — принимает одно из значений: green/yellow/red. 
     green  — всё хорошо; 
     yellow — какие-то шарды отсутствуют/инициализируются,
              но оставшихся кластеру достаточно, чтобы собраться в консистентное состояние; 
     red    — всё плохо, каким-то индексам не хватает шардов до 100% целостности, 
              беда, трагедия, будите админа (но новые данные кластер, тем не менее, принимает).

- number_of_nodes/number_of_data_nodes — общее количество нод в кластере, 
  количество дата-нод. Мониторить их изменение, потому что иногда
  (крайне редко) случаются ситуации, когда какая-то из нод залипла под нагрузкой
  и вывалилась из кластера, но потребляет ресурсы и держит порт открытым. 
  Такое поведение не отлавливается стандартным мониторингом сервисов (уровня ниже),
  но на целостность кластера влияет и ещё как.

- relocating_shards — шарды, находящиеся в процессе ребаланса, 
  перемещаются с одной дата-ноды на другую.

- initializing_shards — инициализирующися шарды. Метрика отличается
  от нуля только в моменты, когда создаются новые индексы и эластик 
  распределяет их шарды по нодам. Ситуация вполне нормальная, 
  но только если этот процесс не длится дольше некоторого времени.
  Время вычисляется эмпирическим путём, Пример в ±10 минут. Если дольше — что-то не то, алерт.

- unassigned_shards — количество неназначенных шард. Значение метрики не равное нулю —
  это очень плохой признак. Либо из кластера выпала нода, либо не хватает места для 
  размещения, либо какая-то другая причина и нужно незамедлительно разбираться.

- number_of_pending_tasks — количество задач в очереди на исполнение. 
  Если не равно нулю — теряем реалтайм, кластер не успевает.

- task_max_waiting_in_queue_millis — среднее время ожидания задачи в 
  очереди на исполнение (в мс.). Аналогично предыдущей метрике, должно быть нулевым.
 
- active_shards_percent_as_number — количество  активных шардов в процентах. 
  Активные шарды — все, кроме тех, что находятся в состоянии unassigned/initializing. 
  В нормальном состоянии — 100%. 

  
Алармы по этим метрикам поднимаются если:
  - status = red — сразу, yellow — через 10 минут;
  - количество нод меньше зафиксированного количества;
  - количество шард в статусе initializing больше 0 дольше 10 минут;
  - количество шард в статусе unassigned не равно 0 — сразу.

=============================================
	метрики критического влияния на работу кластера не оказывают

=============================================
_cluster/stats

- docs.count — количество проиндексированных записей в кластере по состоянию на текущий момент времени.
  Из этой метрики вычисляется количество новых записей в секунду по простой формуле: 
  rps = (docs.count(t) — docs.count(t-1))/t. И если вдруг rps упал в ноль — аларм.

- indices.count — мы используем Elasticsearch для хранения и оперативного доступа к  логам приложений. 
  Каждый день для логов каждого приложения создаётся новый индекс, и каждый день индексы старше 21 дня 
  удаляются из кластера. Таким образом каждый день создаётся и удаляется одинаковое количество индексов.
  Рост общего количества индексов значит, что либо админы поставили под сбор в эластик логи нового
  приложения, либо сломался скрипт очистки старых индексов. Не критично, но поглядывать нужно.

- fs.free_in_bytes, fs.total_in_bytes, fs.available_in_bytes — информация о файловой системе, 
  хранит данные о суммарном объёме места, доступного всему кластеру.

=============================================
_nodes/stats

- jvm.mem.heap_max_in_bytes — выделенная память в байтах,
- jvm.mem.heap_used_in_bytes — используемая память в байтах, 
- jvm.mem.heap_used_percent — используемая память, в процентах от выделенного Xmx.

   Elasticsearch хранит в оперативной памяти каждой дата-ноды индексную 
   часть каждого шарда принадлежащего этой ноде для осуществления поиска.
   Регулярно приходит Garbage Collector и очищает неиспользуемые пулы памяти.
   Через некоторое время, если данных на ноде много и они перестают помещаться в память, 
   сборщик выполняет очистку всё дольше и дольше, пытаясь найти то, что вообще 
   можно очистить, вплоть до полного stop the world. А из-за того, что кластер 
   Elasticsearch работает со скоростью самой медленной дата-ноды, залипать начинает уже весь кластер. 

- fs.total.total_in_bytes, fs.total.free_in_bytes, fs.total.available_in_bytes 
  метрики по дисковому пространству, доступному каждой ноде. 
  Если значение приближается к watermark.low — аларм.

- http.current_open, http.total_opened — количество открытых http-подключений к нодам
  на момент опроса и общее, накопительный счетчик с момента запуска ноды, 
  из которого легко вычисляется rps.

=============================================
   throttle_time_in_millis — очень интересная метрика, существующая в нескольких секциях на каждой ноде.
     То, из какой секции её собирать, зависит от роли ноды. Метрика показывает время ожидания 
     выполнения операции в миллисекундах, в идеале не должно отличаться от нуля:

- indexing.throttle_time_in_millis — время, которое кластер потратил на
  ожидание при индексации новых данных. Имеет смысл только на нодах, 
  принимающих данные.

- store.throttle_time_in_millis — время, затраченное кластером, 
  на ожидание при записи новых данных на диск. Аналогично метрике выше — 
  имеет смысл только на нодах куда поступают новые данные.

- recovery.throttle_time_in_millis — включает в себя не только время
  ожидания при восстановлении шард (например, после сбоев), но и время 
  ожидания при перемещении шард с ноды на ноду (например, при ребалансе или 
  миграции шард между зонами hot/warm). Метрика особо актуальна на нодах, 
  где данные хранятся долго.

- merges.total_throttled_time_in_millis — общее время, затраченное кластером
  на ожидание объединения сегментов на данной ноде. Накопительный счётчик.

Каких-то конкретных диапазонов верхних значений в которые должны вписываться throttle_times
не существует, это зависит от конкретной инсталляции и вычисляется эмпирическим путём.
В идеале, конечно, должен быть ноль.

=============================================
search — секция, содержащая метрики запросов выполняемых на ноде.
   Имеет ненулевые значения только на нодах с данными. 

- search.query_total — всего запросов на поиск, выполненных на ноде с
  момента её перезагрузки. Из этой метрики вычисляем среднее 
  количество запросов в секунду.

- search.query_time_in_millis — время в миллисекундах, затраченное
  на все операции поиска с момента перезагрузки ноды.

=============================================
thread_pool — группа метрик, описывающих пулы очередей, куда попадают операции на выполнение

- thread_pool.bulk.completed — счётчик, хранящий количество выполненных операций пакетной (bulk)
  записи данных в кластер с момента перезагрузки ноды. Из него вычисляется rps по записи.
- thread_pool.bulk.active — количество задач в очереди на добавление данных на момент опроса, 
  показывает загруженность кластера по записи на текущий момент времени. Если этот параметр 
  выходит за установленный размер очереди, начинает расти следующий счётчик.
- thread_pool.bulk.rejected — счётчик количества отказов по запросам на добавление данных. 
  Имеет смысл только на нодах осуществляющих приём данных. Суммируется накопительным итогом,
  раздельно по нодам, обнуляется в момент полной перезагрузки ноды.

Рост этого показателя — очень плохой признак, который показывает, 
что эластику не хватает ресурсов для приёма новых данных.
=============================================

